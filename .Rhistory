
local$eigenvector_centrality$rank <- order(local$eigenvector_centrality$score, decreasing = T)
# return a list object with a $global and $local sublist, each of which contains the output from all of the different measures which are appropriately named. In the $local sublist, we provide the $rank and $score for each node in the network.
return_list <- list(global = global, local = local)
return(return_list)
}
#######################################################################################
#Landau's h-outputs global stat only works for directed graphs
landau <- function(matrix,directed=TRUE){
if(directed==FALSE){
print("error: this measure may only be used with directed networks")
break;
}
N=dim(matrix)[1]
S=apply(matrix,1,sum)
sum(S-((N-1)/2))
h=12/(N^3-N) * sum(S-((N-1)/2))
results=list(global=h,local=rep(NA,N))
return(results)
}
#######################################################################################
#Kendall's K-outputs global stat only works for directed graphs
kendall <- function(matrix,directed=TRUE){
if(directed==FALSE){
print("error: this measure may only be used with directed networks")
break;
}
N=dim(matrix)[1]
S=apply(matrix,1,sum)
d=(N*(N-1)*(2*N-1))/12-(0.5*sum(S^2))
if((N%%2)==0){
#even
d_max=(1/24)*(N^3-4*N)
} else{
#odd
d_max=(1/24)*(N^3-N)
}
K=1-(d/d_max)
results=list(global=K,local=rep(NA,N))
return(results)
}
#######################################################################################
#m reach degree-requires the keyplayer package in R; outputs local stats
m_degree <- function(matrix,directed=TRUE){
require("keyplayer")
l=mreach.degree(matrix,cmode="outdegree")
results=list(global=NA,local=l)
return(results)
}
#######################################################################################
#m reach closeness-requires the keyplayer package in R; outputs local stats
m_close <- function(matrix,directed=TRUE){
require("keyplayer")
l=mreach.closeness(matrix,cmode="outdegree")
results=list(global=NA,local=l)
return(results)
}
#######################################################################################
#GRC-requires the keyplayer package in R; outputs global and local stats
GRC <- function(matrix,directed=TRUE){
require("keyplayer")
N=dim(matrix)[1]
if(directed==TRUE){
C=mreach.degree(matrix,cmode="outdegree")
}
if(directed==FALSE){
C=mreach.degree(matrix,cmode="all")[,3]
}
C_max=max(C)
GRC=(sum(C_max-C))/(N-1)
results=list(global=GRC,local=C)
return(results)
}
#######################################################################################
#Rooted Depth-requires the igraph package in R; outputs global and local stats
D_root <- function(matrix,directed=TRUE){
require(igraph)
if(directed==FALSE){
print("error: this measure may only be used with directed networks")
break;
}
roots=which(apply(matrix,1,sum)==0)
if(length(roots)==0){
print("error:There are no roots in your network")
break;
}
N=dim(matrix)[1]
graph=graph_from_adjacency_matrix(matrix,mode="directed")
paths=as.matrix(shortest.paths(graph,v=roots))
l=apply(paths,2,mean)
if(l[1]==Inf) {l=rep(NA,length(l))}
D_root=mean(as.vector(paths))
if(D_root==Inf){D_root=NA}
results=list(global=D_root,local=l)
return(results)
}
calculate_analytical_hierarhy_measures <- function(sociomatrix,
mode = "directed"){
#statistics using igraph
require(igraph)
sociomatrix <- graph.adjacency(sociomatrix, mode = mode)
#calculate global scores
global <- list()
global$degree_centralization <- centralization.degree (sociomatrix, mode = "all")$centralization
global$closeness_centralization <- centralization.closeness (sociomatrix, mode = "all")$centralization
global$betweenness_centralization <-  centralization.betweenness (sociomatrix, directed = TRUE)$centralization
global$eigenvector_centralization <- centralization.evcent (sociomatrix, directed = TRUE)$centralization
#calculate local scores
local <- list()
local$degree_centrality$score <- centralization.degree (sociomatrix, mode = "all")$res
local$degree_centrality$rank <- order(local$degree_centrality$score, decreasing = T)
local$closeness_centrality$score <- centralization.closeness (sociomatrix, mode = "all")$res
local$closeness_centrality$rank <- order(local$closeness_centrality$score, decreasing = T)
local$betweenness_centrality$score <-  centralization.betweenness (sociomatrix, directed = TRUE)$res
local$betweenness_centrality$rank <- order(local$betweenness_centrality$score, decreasing = T)
local$eigenvector_centrality$score <- centralization.evcent (sociomatrix, directed = TRUE)$vector
local$eigenvector_centrality$rank <- order(local$eigenvector_centrality$score, decreasing = T)
# return a list object with a $global and $local sublist, each of which contains the output from all of the different measures which are appropriately named. In the $local sublist, we provide the $rank and $score for each node in the network.
return_list <- list(global = global, local = local)
return(return_list)
}
data=read.csv("C:\\Users\\admin-ccook\\Desktop\\save_G_Net.csv",header=T)
data=read.csv("C:\\Users\\admin-ccook\\Desktop\\save_G_Net.csv",header=T)
pairs(data[,-c(1,4,5,7)])
pairs(data[,-c(1,4,5,7)],cex.labels=2)
#calculate measures for all networks
#works on Matt's Computer
#preliminaries
rm(list = ls())
#load in functions
source("./Scripts/calculate_analytical_hierarchy_measures.R")
source("./Scripts/score_leadership_rank.R")
source("./Scripts/multi_plot.R")
#load data
load("./Data/Network_Data.Rdata")
# calculate measures for all networks
Measures <- vector(length = length(Network_Data), mode = "list")
for(i in 1:length(Network_Data)){
print(i)
Measures[[i]] <- calculate_analytical_hierarhy_measures(
sociomatrix = Network_Data[[i]]$sociomatrix,
mode = Network_Data[[i]]$mode
)
}
#populate dataframe with global measures
global_measures <- data.frame(matrix(0,
nrow = length(Measures),
ncol = length(Measures[[1]]$global)))
for(i in 1:length(Measures)){
global_measures[i,] <- unlist(Measures[[i]]$global)
}
colnames(global_measures) <- names((Measures[[1]]$global))
rownames(global_measures) <- names(Network_Data)
save(global_measures, file = "./Data/global_hierarchy_measures.Rdata")
multi_plot(data = global_measures,
pdf_name = "Global_Measures",
output_pdf = F,
2:4)
#now score against
measure_scores <- score_leadership_rank(Network_Data = Network_Data,
Measures = Measures)
multi_plot(data = measure_scores,
pdf_name = "Measure_Scores",
output_pdf = T)
colMeans(measure_scores[1:17,])
colMeans(measure_scores[1:29,])
library(ggplot2)
library(tm)
library(MCMCpack)
install.packages("MCMCpack")
simulateCorpus <- function(
M, # number of documents
nTerms,
docLengths,
K,  	# Number of Topics
alphA, 	# parameter for symmetric
# Document/Topic dirichlet distribution
betA, 	# parameter for Topic/Term dirichlet distribution
Alpha=rep(alphA,K), # number-of-topics length vector
# set to symmetric alpha parameter
# across all topics
Beta=rep(betA,nTerms))  # number-of-terms length vector
# set to symmetric beta parameter
# across all terms
{
# Labels
Terms <- paste("Term",seq(nTerms))
Topics <- paste("Topic", seq(K))
Documents <- paste("Document", seq(M))
## Generate latent topic and term distributions
# "True" Document/Topic distribution matrix
Theta <- rdirichlet(M, Alpha)
colnames(Theta) <- Topics
rownames(Theta) <- Documents
# "True" Topic/Term Distribution Matrix
Phi <- rdirichlet(K, Beta)
colnames(Phi) <- Terms
rownames(Phi) <- Topics
## Function to generate individual document
generateDoc <- function(docLength, topic_dist, terms_topics_dist){
# docLength is specific document length
# topic_dist is specific topic distribution for this document
# terms_topics_dist is terms distribution matrix over all topics
document <- c()
for (i in seq(docLength)){
# For each word in a document,
# choose a topic from that
# document's topic distribution
topic <- rmultinom(1, 1, topic_dist)
# Then choose a term from that topic's term distribution
term <- rmultinom(1, 1, terms_topics_dist[topic,])
# and append term to document vector
document <- c(document,
colnames(terms_topics_dist)[which.max(term)])
}
return(document)
}
## generate "observed" corpus as list of terms
corpus <- list()
for (i in seq(M)){
corpus[[i]] <- generateDoc(docLengths[i], Theta[i,], Phi)
}
## convert document term vectors to frequency vectors
freqsLists <- llply(corpus, table)
## write values to termFreqMatrix
termFreqMatrix <- matrix(nrow=M, ncol=nTerms, 0)
colnames(termFreqMatrix) <- Terms
rownames(termFreqMatrix) <- Documents
for (i in seq(M)){
termFreqMatrix[i,names(freqsLists[[i]])] <- freqsLists[[i]]
}
stopifnot(rowSums(termFreqMatrix) == docLengths)
return(list("docs"=corpus,
'termFreqMatrix'=termFreqMatrix,
"Theta"=Theta,
"Phi"=Phi))
}
simulateCorpus(M=10,nTerms=100,docLengths=60,K=2,alphA=0.2,betA=0.3,)
install.packages("LCA")
library(ggplot2)
library(tm)
library(MCMCpack)
simulateCorpus <- function(
require("LCA")
M, # number of documents
nTerms,
docLengths,
K,  	# Number of Topics
alphA, 	# parameter for symmetric
# Document/Topic dirichlet distribution
betA, 	# parameter for Topic/Term dirichlet distribution
Alpha=rep(alphA,K), # number-of-topics length vector
# set to symmetric alpha parameter
# across all topics
Beta=rep(betA,nTerms))  # number-of-terms length vector
# set to symmetric beta parameter
### Basic LDA Topic Model Simulation ###
### Generate Simulated Corpus ###
library(ggplot2)
library(tm)
library(MCMCpack)
simulateCorpus <- function(
M, # number of documents
nTerms,
docLengths,
K,  	# Number of Topics
alphA, 	# parameter for symmetric
# Document/Topic dirichlet distribution
betA, 	# parameter for Topic/Term dirichlet distribution
Alpha=rep(alphA,K), # number-of-topics length vector
# set to symmetric alpha parameter
# across all topics
Beta=rep(betA,nTerms))  # number-of-terms length vector
# set to symmetric beta parameter
# across all terms
{
require("LCA")
# Labels
Terms <- paste("Term",seq(nTerms))
Topics <- paste("Topic", seq(K))
Documents <- paste("Document", seq(M))
## Generate latent topic and term distributions
# "True" Document/Topic distribution matrix
Theta <- rdirichlet(M, Alpha)
colnames(Theta) <- Topics
rownames(Theta) <- Documents
# "True" Topic/Term Distribution Matrix
Phi <- rdirichlet(K, Beta)
colnames(Phi) <- Terms
rownames(Phi) <- Topics
## Function to generate individual document
generateDoc <- function(docLength, topic_dist, terms_topics_dist){
# docLength is specific document length
# topic_dist is specific topic distribution for this document
# terms_topics_dist is terms distribution matrix over all topics
document <- c()
for (i in seq(docLength)){
# For each word in a document,
# choose a topic from that
# document's topic distribution
topic <- rmultinom(1, 1, topic_dist)
# Then choose a term from that topic's term distribution
term <- rmultinom(1, 1, terms_topics_dist[topic,])
# and append term to document vector
document <- c(document,
colnames(terms_topics_dist)[which.max(term)])
}
return(document)
}
## generate "observed" corpus as list of terms
corpus <- list()
for (i in seq(M)){
corpus[[i]] <- generateDoc(docLengths[i], Theta[i,], Phi)
}
## convert document term vectors to frequency vectors
freqsLists <- llply(corpus, table)
## write values to termFreqMatrix
termFreqMatrix <- matrix(nrow=M, ncol=nTerms, 0)
colnames(termFreqMatrix) <- Terms
rownames(termFreqMatrix) <- Documents
for (i in seq(M)){
termFreqMatrix[i,names(freqsLists[[i]])] <- freqsLists[[i]]
}
stopifnot(rowSums(termFreqMatrix) == docLengths)
return(list("docs"=corpus,
'termFreqMatrix'=termFreqMatrix,
"Theta"=Theta,
"Phi"=Phi))
}
simulateCorpus(M=10,nTerms=100,docLengths=60,K=2,alphA=0.2,betA=0.3,)
### Basic LDA Topic Model Simulation ###
### Generate Simulated Corpus ###
library(ggplot2)
library(tm)
library(MCMCpack)
simulateCorpus <- function(
M, # number of documents
nTerms,
docLength,
K,  	# Number of Topics
alphA, 	# parameter for symmetric
# Document/Topic dirichlet distribution
betA, 	# parameter for Topic/Term dirichlet distribution
Alpha=rep(alphA,K), # number-of-topics length vector
# set to symmetric alpha parameter
# across all topics
Beta=rep(betA,nTerms))  # number-of-terms length vector
# set to symmetric beta parameter
# across all terms
{
require("LCA")
# Labels
Terms <- paste("Term",seq(nTerms))
Topics <- paste("Topic", seq(K))
Documents <- paste("Document", seq(M))
## Generate latent topic and term distributions
# "True" Document/Topic distribution matrix
Theta <- rdirichlet(M, Alpha)
colnames(Theta) <- Topics
rownames(Theta) <- Documents
# "True" Topic/Term Distribution Matrix
Phi <- rdirichlet(K, Beta)
colnames(Phi) <- Terms
rownames(Phi) <- Topics
## Function to generate individual document
generateDoc <- function(docLength, topic_dist, terms_topics_dist){
# docLength is specific document length
# topic_dist is specific topic distribution for this document
# terms_topics_dist is terms distribution matrix over all topics
document <- c()
for (i in seq(docLength)){
# For each word in a document,
# choose a topic from that
# document's topic distribution
topic <- rmultinom(1, 1, topic_dist)
# Then choose a term from that topic's term distribution
term <- rmultinom(1, 1, terms_topics_dist[topic,])
# and append term to document vector
document <- c(document,
colnames(terms_topics_dist)[which.max(term)])
}
return(document)
}
## generate "observed" corpus as list of terms
corpus <- list()
for (i in seq(M)){
corpus[[i]] <- generateDoc(docLengths[i], Theta[i,], Phi)
}
## convert document term vectors to frequency vectors
freqsLists <- llply(corpus, table)
## write values to termFreqMatrix
termFreqMatrix <- matrix(nrow=M, ncol=nTerms, 0)
colnames(termFreqMatrix) <- Terms
rownames(termFreqMatrix) <- Documents
for (i in seq(M)){
termFreqMatrix[i,names(freqsLists[[i]])] <- freqsLists[[i]]
}
stopifnot(rowSums(termFreqMatrix) == docLengths)
return(list("docs"=corpus,
'termFreqMatrix'=termFreqMatrix,
"Theta"=Theta,
"Phi"=Phi))
}
simulateCorpus(M=10,nTerms=100,docLength=60,K=2,alphA=0.2,betA=0.3,)
docLength
### Basic LDA Topic Model Simulation ###
### Generate Simulated Corpus ###
library(ggplot2)
library(tm)
library(MCMCpack)
simulateCorpus <- function(
M, # number of documents
nTerms,
docLengths,
K,  	# Number of Topics
alphA, 	# parameter for symmetric
# Document/Topic dirichlet distribution
betA, 	# parameter for Topic/Term dirichlet distribution
Alpha=rep(alphA,K), # number-of-topics length vector
# set to symmetric alpha parameter
# across all topics
Beta=rep(betA,nTerms))  # number-of-terms length vector
# set to symmetric beta parameter
# across all terms
{
require("LCA")
# Labels
Terms <- paste("Term",seq(nTerms))
Topics <- paste("Topic", seq(K))
Documents <- paste("Document", seq(M))
## Generate latent topic and term distributions
# "True" Document/Topic distribution matrix
Theta <- rdirichlet(M, Alpha)
colnames(Theta) <- Topics
rownames(Theta) <- Documents
# "True" Topic/Term Distribution Matrix
Phi <- rdirichlet(K, Beta)
colnames(Phi) <- Terms
rownames(Phi) <- Topics
## Function to generate individual document
generateDoc <- function(docLengths, topic_dist, terms_topics_dist){
# docLength is specific document length
# topic_dist is specific topic distribution for this document
# terms_topics_dist is terms distribution matrix over all topics
document <- c()
for (i in seq(docLengths)){
# For each word in a document,
# choose a topic from that
# document's topic distribution
topic <- rmultinom(1, 1, topic_dist)
# Then choose a term from that topic's term distribution
term <- rmultinom(1, 1, terms_topics_dist[topic,])
# and append term to document vector
document <- c(document,
colnames(terms_topics_dist)[which.max(term)])
}
return(document)
}
## generate "observed" corpus as list of terms
corpus <- list()
for (i in seq(M)){
corpus[[i]] <- generateDoc(docLengths[i], Theta[i,], Phi)
}
## convert document term vectors to frequency vectors
freqsLists <- llply(corpus, table)
## write values to termFreqMatrix
termFreqMatrix <- matrix(nrow=M, ncol=nTerms, 0)
colnames(termFreqMatrix) <- Terms
rownames(termFreqMatrix) <- Documents
for (i in seq(M)){
termFreqMatrix[i,names(freqsLists[[i]])] <- freqsLists[[i]]
}
stopifnot(rowSums(termFreqMatrix) == docLengths)
return(list("docs"=corpus,
'termFreqMatrix'=termFreqMatrix,
"Theta"=Theta,
"Phi"=Phi))
}
simulateCorpus(M=10,nTerms=100,docLengths=60,K=2,alphA=0.2,betA=0.3)
library(XLConnectJars)
library(XLConnect)
install.packages("XLConnect")
library(XLConnect)
install.packages("XLConnectJars")
library(XLConnectJars)
library(XLConnect)
wb <- loadWorkbook("frydata.xlsx")
install.packages("xlsx")
library(xlsx)
library(xlsx)
setwd("~/GitHub/Hierarchy_In_Networks")
source("./Scripts/calculate_analytical_hierarchy_measures.R")
source("./Scripts/score_leadership_rank.R")
source("./Scripts/multi_plot.R")
source('./Scripts/generate_hierarchy_dataset.R')
source('./Scripts/calculate_descriptive_statistics.R')
=======
source('~/Dropbox/SoDA_502/Hierarchy_In_Networks/Scripts/generate_hierarchy_dataset.R')
#for better plotting
#devtools::install_github("matthewjdenny/SpeedReader")
library(SpeedReader)
#load data
>>>>>>> Stashed changes
load("./Data/Network_Data.Rdata")
length(Network_Data[[-c(100,52:54,128,78)]])
length(Network_Data[-c(100,52:54,128,78)])
data_list <- generate_hierarchy_dataset(Network_Data[-c(100,52:54,128,78)])
global_measures <- data_list$global_measure_dataframe
multi_plot(data = global_measures,
pdf_name = "Global_Measures",
output_pdf = F,
c(2:5,7))
<<<<<<< Updated upstream
multi_plot(data = data_list$leadership_ranking_scores,
pdf_name = "Measure_Scores",
output_pdf = F)
descriptive_stats <- calculate_descriptive_statistics(Network_Data[-c(100,52:54,128,78)])
head(descriptive_stats)
library(ggbiplot)
library(devtools)
install.packages("ggbiplot")
=======
i  =1
sociomatrix <- graph.adjacency(Network_Data[[i]]$sociomatrix,
mode = Network_Data[[i]]$mode)
igraph::transitivity(sociomatrix, type="weighted")
igraph::transitivity(sociomatrix, type="global")
igraph::graph.density(sociomatrix)
local_statistics <- matrix(0,nrow = length(Network_Data), ncol = 4)
local_statistics[i,1] <- nrow(Network_Data[[i]]$sociomatrix)
local_statistics[i,2] <- sum(Network_Data[[i]]$sociomatrix)
local_statistics[i,3] <- igraph::graph.density(sociomatrix)
local_statistics[i,4] <- igraph::transitivity(sociomatrix, type="global")
local_statistics <- matrix(0,nrow = length(Network_Data), ncol = 4)
for(i in 1:length(Network_Data)){
sociomatrix <- graph.adjacency(Network_Data[[i]]$sociomatrix,
mode = Network_Data[[i]]$mode)
local_statistics[i,1] <- nrow(Network_Data[[i]]$sociomatrix)
local_statistics[i,2] <- sum(Network_Data[[i]]$sociomatrix)
local_statistics[i,3] <- igraph::graph.density(sociomatrix)
local_statistics[i,4] <- igraph::transitivity(sociomatrix, type="global")
}
View(local_statistics)
rownames(local_statistics) <- names(Network_Data)
colnames(local_statistics) <- c("nodes","edges","density","clustering_coefficient")
network_types <- rep("",length(Network_Data))
local_statistics <- data.frame(local_statistics)
View(local_statistics)
local_statistics <- matrix(0,nrow = length(Network_Data), ncol = 4)
network_types <- rep("",length(Network_Data))
for(i in 1:length(Network_Data)){
sociomatrix <- graph.adjacency(Network_Data[[i]]$sociomatrix,
mode = Network_Data[[i]]$mode)
local_statistics[i,1] <- nrow(Network_Data[[i]]$sociomatrix)
local_statistics[i,2] <- sum(Network_Data[[i]]$sociomatrix)
local_statistics[i,3] <- igraph::graph.density(sociomatrix)
local_statistics[i,4] <- igraph::transitivity(sociomatrix, type="global")
network_types[i] <- Network_Data[[i]]$type
}
rownames(local_statistics) <- names(Network_Data)
colnames(local_statistics) <- c("nodes","edges","density","clustering_coefficient")
local_statistics <- data.frame(local_statistics)
unique_types <- unique(network_types)
unique_types <- unique(network_types)
type_statistics <- matrix(0,nrow = length(unique_types), ncol = 4)
for(i in 1:length(unique_types)){
cur <- local_statistics[which(network_types == unique_types[i]),]
type_statistics[i,] <- colMeans(cur)
}
rownames(type_statistics) <- unique_types
colnames(type_statistics) <- c("nodes","edges","density","clustering_coefficient")
type_statistics <- data.frame(type_statistics)
View(type_statistics)
source('~/Dropbox/SoDA_502/Hierarchy_In_Networks/Scripts/calculate_descriptive_statistics.R')
source('./Scripts/calculate_descriptive_statistics.R')
descriptive_stats <- calculate_descriptive_statistics(Network_Data)
network_descriptive_statistics <- descriptive_stats[[1]]
type_descriptive_statistics <- descriptive_stats[[2]]
View(type_descriptive_statistics)
getwd
getwd()
setwd("~/Dropbox/SoDA_502/Hierarchy_In_Networks")
setwd("~/Dropbox/SoDA_502/Hierarchy_In_Networks/Data/UCINET Data")
temp <- igraph::read.graph(file = "allattrs960.##d", format = "dl")
temp<- readLines("allattrs960.##d")
warnings()
temp
lookup <- read.csv("./Data/Network_CSV_Names.txt",
stringsAsFactors = F,
header = F)
UCI_Nets <- vector(mode = "list", length = lenght(lookup))
UCI_Nets <- vector(mode = "list", length = length(lookup))
i = 1
current <- read.csv(paste("./Data/CSVs/",lookup[i],sep = ""),
stringsAsFactors = F,
header = T,
row.names = T)
paste("./Data/CSVs/",lookup[i],sep = "")
lookup <- as.character(read.csv("./Data/Network_CSV_Names.txt",
stringsAsFactors = F,
header = F))
lookup <- read.csv("./Data/Network_CSV_Names.txt",
stringsAsFactors = F,
header = F)
lookup <- as.character(lookup)
lookup <- read.csv("./Data/Network_CSV_Names.txt",
stringsAsFactors = F,
header = F)
lookup <- as.character(lookup[,1])
current <- read.csv(paste("./Data/CSVs/",lookup[i],sep = ""),
stringsAsFactors = F,
header = T,
row.names = T)
current <- read.csv(paste("./Data/CSVs/Networks/",lookup[i],sep = ""),
stringsAsFactors = F,
header = T,
row.names = T)
current <- read.csv(paste("./Data/CSVs/Networks/",lookup[i],sep = ""),
stringsAsFactors = F,
header = T
)
View(current)
?read.csv
current <- read.csv(paste("./Data/CSVs/Networks/",lookup[i],sep = ""),
stringsAsFactors = F,
header = T,
row.names = 1)
View(current)
name <- stringr::str_split(lookup[i],".")[[1]][1]
stringr::str_split(lookup[i],".")
name <- stringr::str_split(lookup[i],"\.")[[1]][1]
name <- stringr::str_split(lookup[i],"\\.")[[1]][1]
name <- stringr::str_replace_all(name," ", "_")
isSymmetric.matrix(current)
load(file = "./Data/Network_Data.Rdata")
types <- lookup <- read.csv("./Data/Network_Type_Codings.csv",
stringsAsFactors = F,
header = T)
types <- lookup <- read.csv("./Data/Network_CSV_Type_Codings.csv",
stringsAsFactors = F,
header = T)
View(types)
types <- lookup <- read.csv("./Data/Network_CSV_Type_Codings.csv",
stringsAsFactors = F,
header = T)[,2:5]
View(types)
types$Need_To_Reverse[i]
types$Need_To_Reverse[i] != ""
current <- (max(current) + 1) - current
View(lookup)
View(current)
current <- read.csv(paste("./Data/CSVs/Networks/",lookup[i],sep = ""),
stringsAsFactors = F,
header = T,
row.names = 1)
load(file = "./Data/Network_Data.Rdata")
#read in UCI Networks
lookup <- read.csv("./Data/Network_CSV_Names.txt",
stringsAsFactors = F,
header = F)
lookup <- as.character(lookup[,1])
types <- lookup <- read.csv("./Data/Network_CSV_Type_Codings.csv",
stringsAsFactors = F,
header = T)[,2:5]
UCI_Nets <- vector(mode = "list", length = length(lookup))
current <- read.csv(paste("./Data/CSVs/Networks/",lookup[i],sep = ""),
stringsAsFactors = F,
header = T,
row.names = 1)
load(file = "./Data/Network_Data.Rdata")
#read in UCI Networks
lookup <- read.csv("./Data/Network_CSV_Names.txt",
stringsAsFactors = F,
header = F)
lookup <- as.character(lookup[,1])
types <- read.csv("./Data/Network_CSV_Type_Codings.csv",
stringsAsFactors = F,
header = T)[,2:5]
UCI_Nets <- vector(mode = "list", length = length(lookup))
current <- read.csv(paste("./Data/CSVs/Networks/",lookup[i],sep = ""),
stringsAsFactors = F,
header = T,
row.names = 1)
View(current)
if(types$Need_To_Reverse[i] != ""){
current <- (max(current) + 1) - current
}
name <- stringr::str_split(lookup[i],"\\.")[[1]][1]
name <- stringr::str_replace_all(name," ", "_")
mode <- "directed"
if(isSymmetric.matrix(current)){
mode <- "undirected"
}
weighted <- TRUE
if(length(unique(current)) < 3){
weighted <- FALSE
}
type <- types$Type[i]
UCI_Nets <- vector(mode = "list", length = length(lookup))
for(i in 1:length(lookup)){
print(i)
current <- read.csv(paste("./Data/CSVs/Networks/",lookup[i],sep = ""),
stringsAsFactors = F,
header = T,
row.names = 1)
if(types$Need_To_Reverse[i] != ""){
current <- (max(current) + 1) - current
}
name <- stringr::str_split(lookup[i],"\\.")[[1]][1]
name <- stringr::str_replace_all(name," ", "_")
mode <- "directed"
if(isSymmetric.matrix(current)){
mode <- "undirected"
}
weighted <- TRUE
if(length(unique(current)) < 3){
weighted <- FALSE
}
type <- types$Type[i]
UCI_Nets[[i]]$sociomatrix <- current
UCI_Nets[[i]]$mode <- mode
UCI_Nets[[i]]$weighted <- wweighted
UCI_Nets[[i]]$type <- type
names(UCI_Nets)[i] <- name
}
UCI_Nets <- vector(mode = "list", length = length(lookup))
for(i in 1:length(lookup)){
print(i)
current <- read.csv(paste("./Data/CSVs/Networks/",lookup[i],sep = ""),
stringsAsFactors = F,
header = T,
row.names = 1)
if(types$Need_To_Reverse[i] != ""){
current <- (max(current) + 1) - current
}
name <- stringr::str_split(lookup[i],"\\.")[[1]][1]
name <- stringr::str_replace_all(name," ", "_")
mode <- "directed"
if(isSymmetric.matrix(current)){
mode <- "undirected"
}
weighted <- TRUE
if(length(unique(current)) < 3){
weighted <- FALSE
}
type <- types$Type[i]
UCI_Nets[[i]]$sociomatrix <- current
UCI_Nets[[i]]$mode <- mode
UCI_Nets[[i]]$weighted <- weighted
UCI_Nets[[i]]$type <- type
names(UCI_Nets)[i] <- name
}
current <- read.csv(paste("./Data/CSVs/Networks/",lookup[i],sep = ""),
stringsAsFactors = F,
header = T,
row.names = 1)
lookup[i]
current <- read.csv(paste("./Data/CSVs/Networks/",lookup[i],sep = ""),
stringsAsFactors = F,
header = T)
View(current)
row.names(current) <- current[,1]
View(types)
UCI_Nets <- vector(mode = "list", length = length(lookup)-2)
for(i in 1:length(lookup)){
print(i)
if(i != 28 & i != 15){
current <- read.csv(paste("./Data/CSVs/Networks/",lookup[i],sep = ""),
stringsAsFactors = F,
header = T,
row.names = 1)
row.names(current) <- current[,1]
if(types$Need_To_Reverse[i] != ""){
current <- (max(current) + 1) - current
}
name <- stringr::str_split(lookup[i],"\\.")[[1]][1]
name <- stringr::str_replace_all(name," ", "_")
mode <- "directed"
if(isSymmetric.matrix(current)){
mode <- "undirected"
}
weighted <- TRUE
if(length(unique(current)) < 3){
weighted <- FALSE
}
type <- types$Type[i]
UCI_Nets[[i]]$sociomatrix <- current
UCI_Nets[[i]]$mode <- mode
UCI_Nets[[i]]$weighted <- weighted
UCI_Nets[[i]]$type <- type
names(UCI_Nets)[i] <- name
}
}
UCI_Nets <- vector(mode = "list", length = length(lookup)-2)
for(i in 1:length(lookup)){
print(i)
if(i != 28 & i != 15){
current <- read.csv(paste("./Data/CSVs/Networks/",lookup[i],sep = ""),
stringsAsFactors = F,
header = T,
row.names = 1)
if(types$Need_To_Reverse[i] != ""){
current <- (max(current) + 1) - current
}
name <- stringr::str_split(lookup[i],"\\.")[[1]][1]
name <- stringr::str_replace_all(name," ", "_")
mode <- "directed"
if(isSymmetric.matrix(current)){
mode <- "undirected"
}
weighted <- TRUE
if(length(unique(current)) < 3){
weighted <- FALSE
}
type <- types$Type[i]
UCI_Nets[[i]]$sociomatrix <- current
UCI_Nets[[i]]$mode <- mode
UCI_Nets[[i]]$weighted <- weighted
UCI_Nets[[i]]$type <- type
names(UCI_Nets)[i] <- name
}
}
UCI_Nets <- vector(mode = "list", length = length(lookup)-2)
counter <- 1
for(i in 1:length(lookup)){
print(i)
if(i != 28 & i != 15){
current <- read.csv(paste("./Data/CSVs/Networks/",lookup[i],sep = ""),
stringsAsFactors = F,
header = T,
row.names = 1)
if(types$Need_To_Reverse[i] != ""){
current <- (max(current) + 1) - current
}
name <- stringr::str_split(lookup[i],"\\.")[[1]][1]
name <- stringr::str_replace_all(name," ", "_")
mode <- "directed"
if(isSymmetric.matrix(current)){
mode <- "undirected"
}
weighted <- TRUE
if(length(unique(current)) < 3){
weighted <- FALSE
}
type <- types$Type[i]
UCI_Nets[[counter]]$sociomatrix <- current
UCI_Nets[[counter]]$mode <- mode
UCI_Nets[[counter]]$weighted <- weighted
UCI_Nets[[counter]]$type <- type
names(UCI_Nets)[counter] <- name
counter <- counter + 1
}
}
UCI_Nets <- vector(mode = "list", length = length(lookup)-2)
counter <- 1
for(i in 1:length(lookup)){
print(i)
if(i != 28 & i != 15){
current <- read.csv(paste("./Data/CSVs/Networks/",lookup[i],sep = ""),
stringsAsFactors = F,
header = T,
row.names = 1)
current <- as.matrix(current)
if(types$Need_To_Reverse[i] != ""){
current <- (max(current) + 1) - current
}
name <- stringr::str_split(lookup[i],"\\.")[[1]][1]
name <- stringr::str_replace_all(name," ", "_")
mode <- "directed"
if(isSymmetric.matrix(current)){
mode <- "undirected"
}
weighted <- TRUE
if(length(unique(current)) < 3){
weighted <- FALSE
}
type <- types$Type[i]
UCI_Nets[[counter]]$sociomatrix <- current
UCI_Nets[[counter]]$mode <- mode
UCI_Nets[[counter]]$weighted <- weighted
UCI_Nets[[counter]]$type <- type
names(UCI_Nets)[counter] <- name
counter <- counter + 1
}
}
Network_Data <- append(Network_Data,UCI_Nets)
save(Network_Data,file = "./Data/Network_Data.Rdata")
rm(list = ls())
# change your working directory to the "Hierarchy_In_Networks" folder location.
# for me, this is:
setwd("~/Dropbox/SoDA_502/Hierarchy_In_Networks")
#load in functions
source("./Scripts/calculate_analytical_hierarchy_measures.R")
source("./Scripts/score_leadership_rank.R")
source("./Scripts/multi_plot.R")
source('./Scripts/generate_hierarchy_dataset.R')
source('./Scripts/calculate_descriptive_statistics.R')
library(SpeedReader)
load("./Data/Network_Data.Rdata")
data_list <- generate_hierarchy_dataset(Network_Data)
test <- Network_Data[[100]]
test2<- test[[1]]
View(test2)
test2 <- matrix(as.numeric(test2),nrow(test2),ncol(test2))
View(test2)
Network_Data[[100]]$sociomatrix <- test2
data_list <- generate_hierarchy_dataset(Network_Data)
global_measures <- data_list$global_measure_dataframe
save(global_measures, file = "./Data/global_hierarchy_measures.Rdata")
multi_plot(data = data_list$global_measure_dataframe,
pdf_name = "Global_Measures",
output_pdf = F,
c(2:5,7))
View(global_measures)
multi_plot(data = data_list$global_measure_dataframe,
pdf_name = "Global_Measures",
output_pdf = F,
c(2:5,7))
View(global_measures)
which(row.names(global_measures) == "mb031s01nets2")
#deal with one other weird network
global_measures <- global_measures[-100,]
save(global_measures, file = "./Data/global_hierarchy_measures.Rdata")
multi_plot(data = data_list$global_measure_dataframe[-100,],
pdf_name = "Global_Measures",
output_pdf = F,
c(2:5,7))
load("./Data/global_hierarchy_measures.Rdata")
pca <- with(global_measures, prcomp(~degree_centralization +
closeness_centralization +
betweenness_centralization +
eigenvector_centralization +
landau +
kendall +
GRC,
scale = TRUE,
center = TRUE))
plot(pca, type = "l")
pca.g <- ggbiplot(pca, choices = c(1,2),
obs.scale = 1,
var.scale = 1,
ellipse = TRUE,
circle = TRUE)
library(ggbiplot)
pca.g <- ggbiplot(pca, choices = c(1,2),
obs.scale = 1,
var.scale = 1,
ellipse = TRUE,
circle = TRUE)
pca.g
multi_plot(data = data_list$global_measure_dataframe[-100,],
pdf_name = "Global_Measures",
output_pdf = F,
c(2:5,7))
which(row.names(global_measures) == "drugnet")
global_measures <- global_measures[-which(row.names(global_measures) == "drugnet"),]
global_measures <- global_measures[-which(row.names(global_measures) == "Terro_4275"),]
multi_plot(data = global_measures,
pdf_name = "Global_Measures",
output_pdf = F,
c(2:5,7))
global_measures <- global_measures[-which(row.names(global_measures) == "drug_net_61"),]
View(global_measures)
global_measures <- global_measures[-which(row.names(global_measures) == "Koster_data8"),]
save(global_measures, file = "./Data/global_hierarchy_measures.Rdata")
multi_plot(data = global_measures,
pdf_name = "Global_Measures",
output_pdf = F,
c(2:5,7))
global_measures <- global_measures[-which(row.names(global_measures) == "CITES"),]
multi_plot(data = global_measures,
pdf_name = "Global_Measures",
output_pdf = F,
c(2:5,7))
global_measures <- data_list$global_measure_dataframe
#deal with weird networks
global_measures <- global_measures[-100,]
global_measures <- global_measures[-which(row.names(global_measures) == "drugnet"),]
global_measures <- global_measures[-which(row.names(global_measures) == "Terro_4275"),]
global_measures <- global_measures[-which(row.names(global_measures) == "drug_net_61"),]
global_measures <- global_measures[-which(row.names(global_measures) == "Koster_data8"),]
View(global_measures)
global_measures <- global_measures[-which(row.names(global_measures) == "CITIES"),]
View(global_measures)
multi_plot(data = global_measures,
pdf_name = "Global_Measures",
output_pdf = F,
c(2:5,7))
global_measures <- data_list$global_measure_dataframe
which(row.names(global_measures) == "CITIES")
Network_Data[[52]]$type <- "interaction"
save(Network_Data,file = "./Data/Network_Data.Rdata")
global_measures <- data_list$global_measure_dataframe
#deal with weird networks
global_measures <- global_measures[-100,]
global_measures <- global_measures[-which(row.names(global_measures) == "drugnet"),]
global_measures <- global_measures[-which(row.names(global_measures) == "Terro_4275"),]
global_measures <- global_measures[-which(row.names(global_measures) == "drug_net_61"),]
global_measures <- global_measures[-which(row.names(global_measures) == "Koster_data8"),]
global_measures <- global_measures[-which(row.names(global_measures) == "CITIES"),]
save(global_measures, file = "./Data/global_hierarchy_measures.Rdata")
multi_plot(data = global_measures,
pdf_name = "Global_Measures",
output_pdf = F,
c(2:5,7))
pca <- with(global_measures, prcomp(~degree_centralization +
closeness_centralization +
betweenness_centralization +
eigenvector_centralization +
landau +
kendall +
GRC,
scale = TRUE,
center = TRUE))
pca.g <- ggbiplot(pca, choices = c(1,2),
obs.scale = 1,
var.scale = 1,
ellipse = TRUE,
circle = TRUE)
pca.g
?ggbiplot
plot(pca, type = "l")
